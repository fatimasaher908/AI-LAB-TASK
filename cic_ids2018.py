# -*- coding: utf-8 -*-
"""CIC-IDS2018.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11D_WYE_Pmu4bByr2Z50wlm_v7VdtkMSB
"""



"""1. Mount Google drive"""

from google.colab import drive
drive.mount('/content/drive')

"""2. Import Dataset Pandas"""

!pip install -U gdown

import gdown

# Replace with your actual file ID
file_id = "1r59ncZKsikao7W6k7oOBD7SmYc5wHfKN"
url = f"https://drive.google.com/uc?id={file_id}"

# Choose any filename you want
output = "cicids_sample.csv"

# Download
gdown.download(url, output, quiet=False)

import pandas as pd

df = pd.read_csv("cicids_sample.csv")
df.head()

df.tail()

import matplotlib.pyplot as plt
df['Fwd Pkt Len Max'].value_counts().plot(kind='barh')

df['Tot Fwd Pkts'].value_counts().plot(kind='pie')

df['Protocol'].value_counts().plot(kind='hist')

type(df)

df['Fwd Pkt Len Max'].plot(kind='line', title='Fwd Pkt Len Max over Rows')

df.shape

df.isnull().sum()

df.duplicated().sum()

from sklearn.model_selection import train_test_split
X = df.drop('Label', axis=1)  # All columns except the target
y = df['Label']               # The target column

# Step 1: First split into train and temp (test + val)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 2: Split temp into validation and test sets
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

print("Train:", X_train.shape)
print("Validation:", X_val.shape)
print("Test:", X_test.shape)

# Total number of rows
total_rows = len(X)  # or len(df)

# Individual counts
train_pct = len(X_train) / total_rows * 100
val_pct = len(X_val) / total_rows * 100
test_pct = len(X_test) / total_rows * 100

# Print nicely
print(f"Train set: {train_pct:.2f}%")
print(f"Validation set: {val_pct:.2f}%")
print(f"Test set: {test_pct:.2f}%")

df.shape

